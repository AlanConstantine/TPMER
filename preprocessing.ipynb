{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tools import *\n",
    "from CONSTANT import *\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pd.set_option(\"display.max_info_columns\", 1300)\n",
    "\n",
    "import gc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HKU956"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# threshold determining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>song_no</th>\n",
       "      <th>song_id</th>\n",
       "      <th>valence_rating</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal_rating</th>\n",
       "      <th>arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hku1919</td>\n",
       "      <td>16</td>\n",
       "      <td>370177</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hku1919</td>\n",
       "      <td>8</td>\n",
       "      <td>1119687</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hku1919</td>\n",
       "      <td>18</td>\n",
       "      <td>77933</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hku1919</td>\n",
       "      <td>14</td>\n",
       "      <td>238585</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hku1919</td>\n",
       "      <td>20</td>\n",
       "      <td>1168711</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  song_no  song_id  valence_rating  valence  arousal_rating  \\\n",
       "0        hku1919       16   370177             9.3        1             1.0   \n",
       "1        hku1919        8  1119687             9.8        1            -3.0   \n",
       "2        hku1919       18    77933            -0.1        0             1.9   \n",
       "3        hku1919       14   238585             1.0        1            -1.8   \n",
       "4        hku1919       20  1168711             0.2        1            -3.4   \n",
       "\n",
       "   arousal  \n",
       "0        1  \n",
       "1        0  \n",
       "2        1  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_rating = pd.read_csv(r'./HKU956/3. AV_ratings_duration.csv')\n",
    "av_rating['valence'] = av_rating['valence'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "av_rating['arousal'] = av_rating['arousal'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "del av_rating['play_duration']\n",
    "av_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>song_no</th>\n",
       "      <th>song_id</th>\n",
       "      <th>valence_rating</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal_rating</th>\n",
       "      <th>arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>hku1929</td>\n",
       "      <td>7</td>\n",
       "      <td>1119024</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    participant_id  song_no  song_id valence_rating  valence  arousal_rating  \\\n",
       "239        hku1929        7  1119024                       1             6.0   \n",
       "\n",
       "     arousal  \n",
       "239        1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# av_rating[av_rating['valence_rating']==' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minmax_scale(av_rating['valence_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clutering before minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#4EACC5\", \"#FF9C34\", \"#4E9A06\"]\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(av_rating[['valence_rating', 'arousal_rating']])\n",
    "plt.scatter(y=av_rating['arousal_rating'], x=av_rating['valence_rating'], \n",
    "            facecolors='none', edgecolors=['#4EACC5' if i==0 else '#FF9C34' for i in kmeans.labels_ ], s=4)\n",
    "plt.ylabel('arousal')\n",
    "plt.xlabel('valence')\n",
    "plt.plot(kmeans.cluster_centers_.T[0], kmeans.cluster_centers_.T[1], c='red', marker=\"o\", markersize=5)\n",
    "threshold = kmeans.cluster_centers_.sum(axis=0)/2\n",
    "plt.plot(threshold[0], threshold[1], c='red', marker=\"X\", markersize=10)\n",
    "kmeans.cluster_centers_.sum(axis=0)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>song_no</th>\n",
       "      <th>song_id</th>\n",
       "      <th>valence_rating</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal_rating</th>\n",
       "      <th>arousal</th>\n",
       "      <th>valence_label</th>\n",
       "      <th>arousal_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hku1919</td>\n",
       "      <td>16</td>\n",
       "      <td>370177</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hku1919</td>\n",
       "      <td>8</td>\n",
       "      <td>1119687</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hku1919</td>\n",
       "      <td>18</td>\n",
       "      <td>77933</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hku1919</td>\n",
       "      <td>14</td>\n",
       "      <td>238585</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hku1919</td>\n",
       "      <td>20</td>\n",
       "      <td>1168711</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  song_no  song_id  valence_rating  valence  arousal_rating  \\\n",
       "0        hku1919       16   370177             9.3        1             1.0   \n",
       "1        hku1919        8  1119687             9.8        1            -3.0   \n",
       "2        hku1919       18    77933            -0.1        0             1.9   \n",
       "3        hku1919       14   238585             1.0        1            -1.8   \n",
       "4        hku1919       20  1168711             0.2        1            -3.4   \n",
       "\n",
       "   arousal  valence_label  arousal_label  \n",
       "0        1              1              0  \n",
       "1        0              1              0  \n",
       "2        1              0              1  \n",
       "3        0              0              0  \n",
       "4        0              0              0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midpoint = kmeans.cluster_centers_.sum(axis=0)/2\n",
    "av_rating['valence_label'] = av_rating['valence_rating'].apply(lambda x: 1 if x>midpoint[0] else 0)\n",
    "av_rating['arousal_label'] = av_rating['arousal_rating'].apply(lambda x: 1 if x>midpoint[1] else 0)\n",
    "av_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    489\n",
       "0    467\n",
       "Name: valence_label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_rating['valence_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    502\n",
       "0    454\n",
       "Name: arousal_label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_rating['arousal_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# signal processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_processer(user, signal_name, signal_files, win_size=4, step=2):\n",
    "    all_signals = {}\n",
    "    tmp_signals = []\n",
    "    va_info_col = ['participant_id', 'song_no', 'song_id', 'valence_rating',\n",
    "                   'valence', 'arousal_rating', 'arousal', 'play_duration']\n",
    "    for file in signal_files:\n",
    "        try:\n",
    "            filename = os.path.split(file)[-1]\n",
    "            filename, file_extension = os.path.splitext(filename)\n",
    "            if file_extension != '.csv':\n",
    "                continue\n",
    "            # songno, songid = filename.split('_')\n",
    "            \n",
    "            signal = pd.read_csv(file, header=None).iloc[:,0].values\n",
    "\n",
    "            # bandpass or lowpass filtering & resampling\n",
    "            if signal_name == 'EDA':\n",
    "                signal = butter_lowpass_filter(signal, cutOff=CUTOFF['EDA'], fs=SAMPLERATE['EDA'])\n",
    "                signal = resample_by_interpolation(signal, input_fs=SAMPLERATE['EDA'], output_fs=100)\n",
    "            elif signal_name in ['TEMP', 'BVP']:\n",
    "                signal = butter_bandpass_filter(signal, lowcut=CUTOFF[signal_name][0], highcut=CUTOFF[signal_name][1], fs=SAMPLERATE[signal_name])\n",
    "                signal = resample_by_interpolation(signal, input_fs=SAMPLERATE[signal_name], output_fs=100)\n",
    "            elif signal_name == 'HR':\n",
    "                # signal = chauvenet_filter(signal)\n",
    "                # print(signal)\n",
    "                signal = resample_by_interpolation(signal, input_fs=SAMPLERATE[signal_name], output_fs=100)\n",
    "            else: # IBI\n",
    "                continue\n",
    "\n",
    "            tmp_signals.extend(signal.tolist())\n",
    "            all_signals[filename] = signal\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e, file)\n",
    "            raise e\n",
    "        \n",
    "    signal_max = np.max(tmp_signals)\n",
    "    signal_min = np.min(tmp_signals)\n",
    "\n",
    "    del tmp_signals\n",
    "\n",
    "    signal_df = []\n",
    "\n",
    "    # normalization, segmentation, $ concatenation\n",
    "    for filename, signal in all_signals.items():\n",
    "        song_no, song_id = filename.split('_')\n",
    "        signal = (signal - signal_min) / (signal_max - signal_min)\n",
    "        signal = pd.Series(signal).interpolate().tolist()\n",
    "        \n",
    "        segments = np.array(segment_generator(signal, win_size=win_size*100, step=step*100)[1:])\n",
    "        seg_cols = ['{}_seg{}'.format(signal_name, i) for i in range(segments.shape[1])]\n",
    "        segment_df = pd.DataFrame(columns=seg_cols, data=segments)\n",
    "\n",
    "        segment_df['segment_id'] = segment_df.index.tolist()\n",
    "        segment_df['song_no'] = int(song_no)\n",
    "        segment_df['song_id'] = int(song_id)\n",
    "        segment_df['participant_id'] = user\n",
    "\n",
    "        # va_info = [av_rating[(av_rating['participant_id']==user) & (av_rating['song_no']==int(songno)) & (av_rating['song_id']==int(songid))].values.tolist()[0] for _ in range(len(segments))]\n",
    "        # tmp_va_info = pd.DataFrame(columns=va_info_col, data=va_info)\n",
    "        # segment_df = pd.concat([tmp_va_info, segment_df], axis=1)\n",
    "        \n",
    "        signal_df.append(segment_df)\n",
    "    \n",
    "    return pd.concat(signal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BVP (22727, 404)\n",
      "EDA (22727, 404)\n",
      "HR (22727, 404)\n",
      "TEMP (22727, 404)\n"
     ]
    }
   ],
   "source": [
    "users = os.listdir(HKU_DIR)\n",
    "signal_dfs = {}\n",
    "\n",
    "# for signal_name in ['HR']:\n",
    "for signal_name in SIGNALS:\n",
    "    if signal_name == 'IBI':\n",
    "        continue\n",
    "    signals = []\n",
    "    for user in users:\n",
    "        signal_files = get_folder_files(os.path.join(HKU_DIR, user, signal_name))\n",
    "        signal_df = signal_processer(user, signal_name, signal_files)\n",
    "        signals.append(signal_df)\n",
    "        # break\n",
    "    signals = pd.concat(signals)\n",
    "    # signals.to_csv(os.path.join(PROCESSED_DIR, 'HKU956', '{}.csv'.format(signal_name)), index=False)\n",
    "    print(signal_name, signals.shape)\n",
    "    signal_dfs[signal_name] = signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (22727, 1604)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4024"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bvp_eda_df = signal_dfs['BVP'].merge(signal_dfs['EDA'], on=['segment_id', 'song_no', 'song_id', 'participant_id'], how='left')\n",
    "bvp_eda_hr_df = bvp_eda_df.merge(signal_dfs['HR'], on=['segment_id', 'song_no', 'song_id', 'participant_id'], how='left')\n",
    "del bvp_eda_df\n",
    "bvp_eda_hr_temp_df = bvp_eda_hr_df.merge(signal_dfs['TEMP'], on=['segment_id', 'song_no', 'song_id', 'participant_id'], how='left')\n",
    "del bvp_eda_hr_df\n",
    "print(bvp_eda_hr_temp_df.isnull().sum().sum(), bvp_eda_hr_temp_df.shape)\n",
    "# bvp_eda_hr_temp_df = reduce_mem_usage(bvp_eda_hr_temp_df, un_process=['segment_id', 'song_no', 'song_id', 'participant_id'])\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22727 entries, 0 to 22726\n",
      "Columns: 1608 entries, BVP_seg0 to arousal_label\n",
      "dtypes: float64(1602), int64(5), object(1)\n",
      "memory usage: 279.0+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_signals_df = bvp_eda_hr_temp_df.merge(av_rating, on=['participant_id', 'song_no', 'song_id'])\n",
    "del all_signals_df['segment_id'], all_signals_df['song_no'], bvp_eda_hr_temp_df\n",
    "print(all_signals_df.info())\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_signals_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BVP_seg0</th>\n",
       "      <th>BVP_seg1</th>\n",
       "      <th>BVP_seg2</th>\n",
       "      <th>BVP_seg3</th>\n",
       "      <th>BVP_seg4</th>\n",
       "      <th>BVP_seg5</th>\n",
       "      <th>BVP_seg6</th>\n",
       "      <th>BVP_seg7</th>\n",
       "      <th>BVP_seg8</th>\n",
       "      <th>BVP_seg9</th>\n",
       "      <th>...</th>\n",
       "      <th>TEMP_seg396</th>\n",
       "      <th>TEMP_seg397</th>\n",
       "      <th>TEMP_seg398</th>\n",
       "      <th>TEMP_seg399</th>\n",
       "      <th>valence_rating</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal_rating</th>\n",
       "      <th>arousal</th>\n",
       "      <th>valence_label</th>\n",
       "      <th>arousal_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22727.000000</td>\n",
       "      <td>22727.000000</td>\n",
       "      <td>22727.000000</td>\n",
       "      <td>22727.000000</td>\n",
       "      <td>22727.000000</td>\n",
       "      <td>22727.000000</td>\n",
       "      <td>22727.000000</td>\n",
       "      <td>22727.000000</td>\n",
       "      <td>22727.000000</td>\n",
       "      <td>22727.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>22727.000000</td>\n",
       "      <td>22727.000000</td>\n",
       "      <td>22727.000000</td>\n",
       "      <td>22727.000000</td>\n",
       "      <td>22727.000000</td>\n",
       "      <td>22727.000000</td>\n",
       "      <td>22727.000000</td>\n",
       "      <td>22727.000000</td>\n",
       "      <td>22727.000000</td>\n",
       "      <td>22727.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.496038</td>\n",
       "      <td>0.496020</td>\n",
       "      <td>0.495992</td>\n",
       "      <td>0.495952</td>\n",
       "      <td>0.495902</td>\n",
       "      <td>0.495850</td>\n",
       "      <td>0.495800</td>\n",
       "      <td>0.495756</td>\n",
       "      <td>0.495715</td>\n",
       "      <td>0.495682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305491</td>\n",
       "      <td>0.305353</td>\n",
       "      <td>0.305215</td>\n",
       "      <td>0.305077</td>\n",
       "      <td>2.167497</td>\n",
       "      <td>0.693228</td>\n",
       "      <td>0.939240</td>\n",
       "      <td>0.593479</td>\n",
       "      <td>0.529502</td>\n",
       "      <td>0.517622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.068643</td>\n",
       "      <td>0.068515</td>\n",
       "      <td>0.068588</td>\n",
       "      <td>0.068734</td>\n",
       "      <td>0.068640</td>\n",
       "      <td>0.068745</td>\n",
       "      <td>0.068796</td>\n",
       "      <td>0.068731</td>\n",
       "      <td>0.068860</td>\n",
       "      <td>0.068809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.295021</td>\n",
       "      <td>0.294981</td>\n",
       "      <td>0.294942</td>\n",
       "      <td>0.294903</td>\n",
       "      <td>4.453328</td>\n",
       "      <td>0.461164</td>\n",
       "      <td>4.470232</td>\n",
       "      <td>0.491195</td>\n",
       "      <td>0.499140</td>\n",
       "      <td>0.499700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.035377</td>\n",
       "      <td>0.020129</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.008271</td>\n",
       "      <td>0.017790</td>\n",
       "      <td>0.028889</td>\n",
       "      <td>0.026093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.459080</td>\n",
       "      <td>0.458977</td>\n",
       "      <td>0.458995</td>\n",
       "      <td>0.458759</td>\n",
       "      <td>0.458833</td>\n",
       "      <td>0.459017</td>\n",
       "      <td>0.459079</td>\n",
       "      <td>0.459308</td>\n",
       "      <td>0.459098</td>\n",
       "      <td>0.459067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057375</td>\n",
       "      <td>0.057274</td>\n",
       "      <td>0.057194</td>\n",
       "      <td>0.057152</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.495357</td>\n",
       "      <td>0.495253</td>\n",
       "      <td>0.495269</td>\n",
       "      <td>0.495074</td>\n",
       "      <td>0.495382</td>\n",
       "      <td>0.495100</td>\n",
       "      <td>0.495137</td>\n",
       "      <td>0.495197</td>\n",
       "      <td>0.494969</td>\n",
       "      <td>0.494972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204900</td>\n",
       "      <td>0.204990</td>\n",
       "      <td>0.205080</td>\n",
       "      <td>0.205170</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.534075</td>\n",
       "      <td>0.533800</td>\n",
       "      <td>0.533938</td>\n",
       "      <td>0.533644</td>\n",
       "      <td>0.533482</td>\n",
       "      <td>0.533286</td>\n",
       "      <td>0.533365</td>\n",
       "      <td>0.533292</td>\n",
       "      <td>0.533467</td>\n",
       "      <td>0.533631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473414</td>\n",
       "      <td>0.473142</td>\n",
       "      <td>0.472870</td>\n",
       "      <td>0.472598</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974522</td>\n",
       "      <td>0.958740</td>\n",
       "      <td>0.979730</td>\n",
       "      <td>0.992339</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999411</td>\n",
       "      <td>0.989169</td>\n",
       "      <td>0.973463</td>\n",
       "      <td>0.975853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997564</td>\n",
       "      <td>0.997448</td>\n",
       "      <td>0.997332</td>\n",
       "      <td>0.997216</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 1607 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           BVP_seg0      BVP_seg1      BVP_seg2      BVP_seg3      BVP_seg4  \\\n",
       "count  22727.000000  22727.000000  22727.000000  22727.000000  22727.000000   \n",
       "mean       0.496038      0.496020      0.495992      0.495952      0.495902   \n",
       "std        0.068643      0.068515      0.068588      0.068734      0.068640   \n",
       "min        0.035377      0.020129      0.008300      0.000866      0.000000   \n",
       "25%        0.459080      0.458977      0.458995      0.458759      0.458833   \n",
       "50%        0.495357      0.495253      0.495269      0.495074      0.495382   \n",
       "75%        0.534075      0.533800      0.533938      0.533644      0.533482   \n",
       "max        1.000000      0.974522      0.958740      0.979730      0.992339   \n",
       "\n",
       "           BVP_seg5      BVP_seg6      BVP_seg7      BVP_seg8      BVP_seg9  \\\n",
       "count  22727.000000  22727.000000  22727.000000  22727.000000  22727.000000   \n",
       "mean       0.495850      0.495800      0.495756      0.495715      0.495682   \n",
       "std        0.068745      0.068796      0.068731      0.068860      0.068809   \n",
       "min        0.002007      0.008271      0.017790      0.028889      0.026093   \n",
       "25%        0.459017      0.459079      0.459308      0.459098      0.459067   \n",
       "50%        0.495100      0.495137      0.495197      0.494969      0.494972   \n",
       "75%        0.533286      0.533365      0.533292      0.533467      0.533631   \n",
       "max        1.000000      0.999411      0.989169      0.973463      0.975853   \n",
       "\n",
       "       ...   TEMP_seg396   TEMP_seg397   TEMP_seg398   TEMP_seg399  \\\n",
       "count  ...  22727.000000  22727.000000  22727.000000  22727.000000   \n",
       "mean   ...      0.305491      0.305353      0.305215      0.305077   \n",
       "std    ...      0.295021      0.294981      0.294942      0.294903   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.057375      0.057274      0.057194      0.057152   \n",
       "50%    ...      0.204900      0.204990      0.205080      0.205170   \n",
       "75%    ...      0.473414      0.473142      0.472870      0.472598   \n",
       "max    ...      0.997564      0.997448      0.997332      0.997216   \n",
       "\n",
       "       valence_rating       valence  arousal_rating       arousal  \\\n",
       "count    22727.000000  22727.000000    22727.000000  22727.000000   \n",
       "mean         2.167497      0.693228        0.939240      0.593479   \n",
       "std          4.453328      0.461164        4.470232      0.491195   \n",
       "min         -9.500000      0.000000       -9.300000      0.000000   \n",
       "25%         -0.600000      0.000000       -2.200000      0.000000   \n",
       "50%          2.400000      1.000000        1.400000      1.000000   \n",
       "75%          5.800000      1.000000        4.200000      1.000000   \n",
       "max          9.900000      1.000000        9.800000      1.000000   \n",
       "\n",
       "       valence_label  arousal_label  \n",
       "count   22727.000000   22727.000000  \n",
       "mean        0.529502       0.517622  \n",
       "std         0.499140       0.499700  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         1.000000       1.000000  \n",
       "75%         1.000000       1.000000  \n",
       "max         1.000000       1.000000  \n",
       "\n",
       "[8 rows x 1607 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_signals_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_signals_df.to_csv(r'./processed_signal/HKU956/400_4s_step_2s.csv', index=False)\n",
    "# all_signals_df.to_pickle(r'./processed_signal/HKU956/400_4s_step_2s.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12034\n",
       "0    10693\n",
       "Name: valence_label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_signals_df['valence_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11764\n",
       "0    10963\n",
       "Name: arousal_label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_signals_df['arousal_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generating train_test spliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [fea for fea in all_signals_df.columns.values if fea.split('_')[0] in SIGNALS]\n",
    "target_cols = ['valence', 'arousal', 'arousal_rating', 'valence_rating', 'arousal_label', 'valence_label']\n",
    "group_cols = ['participant_id', 'song_id']\n",
    "\n",
    "spliter = {'cv': [], 'loso': [], 'loao': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=31)\n",
    "for train_index, test_index in skf.split(all_signals_df[feature_cols], all_signals_df['valence_label']):\n",
    "    spliter['cv'].append({'train_index': train_index, 'test_index': test_index})\n",
    "\n",
    "loso_skgf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=31)\n",
    "for train_index, test_index in loso_skgf.split(all_signals_df[feature_cols], all_signals_df['valence_label'], groups=all_signals_df['participant_id']):\n",
    "    spliter['loso'].append({'train_index': train_index, 'test_index': test_index})\n",
    "\n",
    "loao_skgf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=31)\n",
    "for train_index, test_index in loao_skgf.split(all_signals_df[feature_cols], all_signals_df['valence_label'], groups=all_signals_df['song_id']):\n",
    "    spliter['loao'].append({'train_index': train_index, 'test_index': test_index})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./processed_signal/HKU956/400_4s_step_2s_spliter.pkl saved done!\n"
     ]
    }
   ],
   "source": [
    "save_model(r'./processed_signal/HKU956/400_4s_step_2s_spliter.pkl', spliter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "spliter = load_model(r'./processed_signal/HKU956/400_4s_step_2s_spliter.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18089 4638\n",
      "18512 4215\n",
      "18181 4546\n"
     ]
    }
   ],
   "source": [
    "print(len(spliter['loso'][0]['train_index']), len(spliter['loso'][0]['test_index']))\n",
    "print(len(spliter['loao'][0]['train_index']), len(spliter['loao'][0]['test_index']))\n",
    "print(len(spliter['cv'][0]['train_index']), len(spliter['cv'][0]['test_index']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_signals(df, target='valence'):\n",
    "    bvp_cols = [fea for fea in all_signals_df.columns.values if fea.split('_')[0] in ['BVP']]\n",
    "    eda_cols = [fea for fea in all_signals_df.columns.values if fea.split('_')[0] in ['EDA']]\n",
    "    temp_cols = [fea for fea in all_signals_df.columns.values if fea.split('_')[0] in ['TEMP']]\n",
    "    hr_cols = [fea for fea in all_signals_df.columns.values if fea.split('_')[0] in ['HR']]\n",
    "\n",
    "    target_cols = ['valence', 'arousal', 'arousal_rating', 'valence_rating']\n",
    "    group_cols = ['participant_id', 'song_id']\n",
    "\n",
    "    signal_concats = []\n",
    "    for bvp, eda, temp, hr in zip(df[bvp_cols].values, df[eda_cols].values, df[temp_cols].values, df[hr_cols].values):\n",
    "        signal_concats.append([bvp, eda, temp, hr])\n",
    "\n",
    "    return np.array(signal_concats), df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = spliter['loso'][0]['train_index']\n",
    "test_index = spliter['loso'][0]['test_index']\n",
    "\n",
    "target_col = 'valence'\n",
    "\n",
    "df = pd.read_pickle(r'./processed_signal/HKU956/400_4s_step_2s.pkl')\n",
    "# train_df = df.iloc[train_index]\n",
    "# test_df = df.iloc[test_index]\n",
    "X, y = join_signals(df, target='valence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18089, 4, 400), (18089,), (4638, 4, 400), (4638,))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = X[train_index], y[train_index], X[test_index], y[test_index]\n",
    "train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "13e5bb8e298584c2ac3139085defc83b48703aa1260fc05df28d0eb98c842854"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
