{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "from CONSTANT import *\n",
    "from tools import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import (TensorDataset, DataLoader, SequentialSampler, WeightedRandomSampler)\n",
    "\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoderLayer, TransformerDecoder\n",
    "\n",
    "from models import *\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "use_cuda = False\n",
    "valid='loso'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and use_cuda else 'cpu')\n",
    "print('using', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskp = .25\n",
    "np.random.choice([0, 1], size=4, p=[maskp, 1-maskp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 0, 0, 1],\n",
       "       [0, 1, 0, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 1, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 1, 0, 1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.binomial(n=1, p=0.5, size=[10, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from representation.SigRepre import MultiSignalRepresentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DataPrepare(object):\n",
    "\n",
    "#     def __init__(self,\n",
    "#                  args,\n",
    "#                  target,\n",
    "#                  data,\n",
    "#                  train_index,\n",
    "#                  test_index,\n",
    "#                  device,\n",
    "#                  batch_size=64):\n",
    "\n",
    "#         self.args = args\n",
    "\n",
    "#         X, y = join_signals(data, target=target)\n",
    "#         xtrain, ytrain, xtest, ytest = X[train_index], y[train_index], X[\n",
    "#             test_index], y[test_index]\n",
    "\n",
    "#         if self.args.debug:\n",
    "#             xtrain, ytrain, xtest, ytest = xtrain[:\n",
    "#                                                   1000], ytrain[:1000], xtest[:100], ytest[:100]\n",
    "\n",
    "#         print(xtrain.shape, ytrain.shape, xtest.shape, ytest.shape)\n",
    "\n",
    "#         xtrain = torch.from_numpy(xtrain).to(torch.float32)\n",
    "#         xtest = torch.from_numpy(xtest).to(torch.float32)\n",
    "\n",
    "#         self.xtrain, self.xtest = xtrain.to(device), xtest.to(device)\n",
    "\n",
    "#         ytrain = torch.from_numpy(ytrain)\n",
    "#         ytest = torch.from_numpy(ytest)\n",
    "\n",
    "#         self.ytrain, self.ytest = ytrain.to(device), ytest.to(device)\n",
    "\n",
    "#         if args.target in ['valence', 'arousal']:\n",
    "#             self.ytrain = self.ytrain.to(torch.float32)\n",
    "#             self.ytest = self.ytest.to(torch.float32)\n",
    "\n",
    "#         self.batch_size = batch_size\n",
    "\n",
    "#     def get_data(self):\n",
    "#         train_data = TensorDataset(self.xtrain, self.ytrain)\n",
    "#         test_data = TensorDataset(self.xtest, self.ytest)\n",
    "\n",
    "#         train_sampler = SequentialSampler(train_data)\n",
    "#         train_dataloader = DataLoader(train_data,\n",
    "#                                       sampler=train_sampler,\n",
    "#                                       batch_size=self.batch_size,\n",
    "#                                       drop_last=False)\n",
    "\n",
    "#         test_sampler = SequentialSampler(test_data)\n",
    "#         test_dataloader = DataLoader(test_data,\n",
    "#                                      sampler=test_sampler,\n",
    "#                                      batch_size=self.batch_size,\n",
    "#                                      drop_last=False)\n",
    "\n",
    "#         return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params(object):\n",
    "    def __init__(self, lr=0.001, epoch=100, valid='loso', target='valence', batch_size=64,):\n",
    "        self.batch_size = batch_size\n",
    "        self.valid = valid\n",
    "        self.target = target\n",
    "        self.epoch = epoch\n",
    "        self.lr = lr\n",
    "        self.metrics_dict = {}\n",
    "        self.debug = True\n",
    "        self.out_channels = 32\n",
    "        self.out_channels = 32\n",
    "        self.hidden_size = 64\n",
    "        self.num_layers = 1\n",
    "        self.fcn_input = 50432\n",
    "        self.dropout=0.2\n",
    "        self.use_cuda=False\n",
    "        self.device=torch.device(\n",
    "            'cuda' if torch.cuda.is_available() and self.use_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spliter = load_model(r'./processed_signal/HKU956/400_4s_step_2s_spliter.pkl')\n",
    "data = pd.read_pickle(r'./processed_signal/HKU956/400_4s_step_2s.pkl')\n",
    "# data = pd.read_csv(r'./processed_signal/HKU956/400_4s_step_2s.csv')\n",
    "\n",
    "for k in spliter[valid]:\n",
    "    train_index = k['train_index']\n",
    "    test_index = k['test_index']\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4, 400) (1000, 1) (100, 4, 400) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "dataprepare = DataPrepare(args=args, target='valence', data=data, train_index=train_index, test_index=test_index, device=device)\n",
    "# train_dataloader, test_dataloader = dataprepare.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = dataprepare.xtest\n",
    "xtrain = dataprepare.xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 4, 400]), torch.Size([1000, 4, 400]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.shape, xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiSignalRepresentation(output_size=40, device=args.device, pretrain=True)\n",
    "model.load_state_dict(torch.load(r'./output/0.0001_256_maskp0.8_checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = MultiSignalRepresentation(output_size=40, device=args.device)\n",
    "# model.load_state_dict(torch.load(r'./representation/mask08ep13.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.MER import MERClassifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fcn = MERClassifer(args, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xtest[:10]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliter = load_model(r'./processed_signal/WESAD/400_4s_step_2s_spliter.pkl')\n",
    "# data = pd.read_pickle(r'./processed_signal/WESAD/400_4s_step_2s.pkl')\n",
    "# # data = pd.read_csv(r'./processed_signal/HKU956/400_4s_step_2s.csv')\n",
    "\n",
    "# for k in spliter[valid]:\n",
    "#     train_index = k['train_index']\n",
    "#     test_index = k['test_index']\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 400])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest = dataprepare.xtest[:8]\n",
    "bvp = xtest[:, 0, :].reshape(-1, 1, 400)\n",
    "bvp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se = SignalEncoder(output_size=64, dropout=0.2)\n",
    "x = se(bvp)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 64])\n",
      "torch.Size([8, 64, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 400])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msr = MultiSignalRepresentation(output_size=64, dropout=0.2)\n",
    "x = msr(xtest, xtest)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SigRep.SigRepSimple(args)\n",
    "# model.load_state_dict(torch.load(r'./output/False_WES_valence_SG_loso_0.0001_512_32/fold4_checkpoint.pt'))\n",
    "# model.fcn = nn.Sequential(\n",
    "#     nn.Linear(40 * 4, 16), nn.ReLU(),\n",
    "#     nn.Linear(16, 8), nn.ReLU(), nn.Dropout(p=args.dropout))\n",
    "# model.regressor = nn.Linear(8, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "from models import CNNBiLSTM, SigRep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = dataprepare.xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SigRep.SigRepSimple(args)\n",
    "model = model.to(device)\n",
    "yhat = model(xtest)\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rnn_torchviz.png'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = CNNBiLSTM.CNNBiLSTM(args)\n",
    "model = model.to(device)\n",
    "yhat = model(xtest)\n",
    "make_dot(yhat, params=dict(list(model.named_parameters()))).render(\"torchviz\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CNN+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 4, 400])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest = dataprepare.xtest[:100]\n",
    "del dataprepare\n",
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtest = xtest.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # https://blog.csdn.net/Cyril_KI/article/details/125439045\n",
    "# # https://github.com/ozancanozdemir/CNN-LSTM/blob/main/cnn-lstm.py\n",
    "\n",
    "# cnns = nn.Sequential(\n",
    "#     nn.Conv1d(4, 32, 3),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.MaxPool1d(kernel_size=2, stride=1),\n",
    "#     nn.BatchNorm1d(32),\n",
    "#     nn.Conv1d(32, 64, 3),\n",
    "#     nn.MaxPool1d(kernel_size=2, stride=1),\n",
    "#     nn.BatchNorm1d(64),\n",
    "#     nn.ReLU(inplace=True),\n",
    "# )\n",
    "\n",
    "# lstm1 = nn.LSTM(input_size=64, \n",
    "#             hidden_size=256,\n",
    "#             num_layers=3, batch_first=True,\n",
    "#             bidirectional=True, dropout=0.5\n",
    "#             )\n",
    "\n",
    "# lstm2 = nn.LSTM(input_size=256, \n",
    "#             hidden_size=256,\n",
    "#             num_layers=3, batch_first=True,\n",
    "#             bidirectional=True, dropout=0.5\n",
    "#             )\n",
    "    \n",
    "\n",
    "# classifier = nn.Sequential(\n",
    "#             nn.Dropout(p=0.5),\n",
    "#             nn.Linear(256, 1024),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(p=0.5),\n",
    "#             nn.Linear(1024, 512),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(512, 2)\n",
    "#         )\n",
    "\n",
    "# cnns.to(device)\n",
    "# lstm1.to(device)\n",
    "# lstm2.to(device)\n",
    "# classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm = nn.Sequential(nn.LSTM(input_size=64, \n",
    "#             hidden_size=256,\n",
    "#             num_layers=3, batch_first=True,\n",
    "#             bidirectional=True, dropout=0.5\n",
    "#             )).to(device)\n",
    "\n",
    "# lstm2 = nn.LSTM(input_size=512, \n",
    "#             hidden_size=512,\n",
    "#             num_layers=3, batch_first=True,\n",
    "#             bidirectional=True, dropout=0.5\n",
    "#             ).to(device)\n",
    "\n",
    "# bn1 = nn.Sequential(nn.BatchNorm1d(256*2),\n",
    "#                     nn.ReLU(inplace=True),\n",
    "#         ).to(device)\n",
    "\n",
    "# bn2 = nn.Sequential(nn.BatchNorm1d(512*2),\n",
    "#                     nn.ReLU(inplace=True),\n",
    "#         ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = cnns(xtest)\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = cnns(xtest) # output [batch_size, channels, seq_len]\n",
    "# x = x.permute(0, 2, 1)\n",
    "# x, _ = lstm(x) # output [batch_size, seq_len, Hin]\n",
    "# x = x.permute(0, 2, 1)\n",
    "# x = bn1(x)  # output [batch_size, Hin, seq_len]\n",
    "# x = x.permute(0, 2, 1)\n",
    "# x, _ = lstm2(x) # output [batch_size, seq_len, Hin]\n",
    "# x = x.permute(0, 2, 1)\n",
    "# x = bn2(x) # output [batch_size, Hin, seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.flatten(start_dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = cnns(xtest) # output [batch_size, channels, seq_len]\n",
    "# x = x.permute(0, 2, 1)\n",
    "# x, _ = lstms(x) # output [batch_size, seq_len, Hin]\n",
    "# # classifier(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class CNNBiLSTM(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.cnns = nn.Sequential(\n",
    "            nn.Conv1d(4, 32, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Conv1d(32, args.out_channels, 3),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.lstm1 = nn.LSTM(input_size=args.out_channels,\n",
    "                             hidden_size=512,\n",
    "                             num_layers=args.num_layers, batch_first=True,\n",
    "                             bidirectional=True\n",
    "                             )\n",
    "\n",
    "        self.lstm2 = nn.LSTM(input_size=512 * 2,\n",
    "                             hidden_size=args.hidden_size,\n",
    "                             num_layers=args.num_layers, batch_first=True,\n",
    "                             bidirectional=True\n",
    "                             )\n",
    "\n",
    "        self.fcn = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(args.fcn_input, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(512, 2)\n",
    "\n",
    "        self.regresser = nn.Linear(512, 1)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        input [batch_size, channels, seq_len]\n",
    "        \"\"\"\n",
    "        x = self.cnns(x)  # output [batch_size, channels, seq_len]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.lstm1(x)  # output [batch_size, seq_len, Hin]\n",
    "        x = self.relu(x)\n",
    "        x, _ = self.lstm2(x)  # output [batch_size, seq_len, Hin]\n",
    "        x = self.relu(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        print(x.shape)\n",
    "        x = self.fcn(x)\n",
    "        if self.args.target in ['valence', 'arousal']:\n",
    "            return self.regresser(x)\n",
    "        else:\n",
    "            output = torch.sigmoid(self.classifier(x))\n",
    "            return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params(object):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.out_channels = 64\n",
    "        self.hidden_size = 256\n",
    "        self.num_layers = 3\n",
    "        self.fcn_input = 201728\n",
    "        self.target = 'valence_label'\n",
    "        self.device = torch.device('cuda')\n",
    "        self.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4, 400) (100, 1) (100, 4, 400) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "args = Params()\n",
    "dataprepare = DataPrepare(args, device=args.device, target='valence', data=data, train_index=train_index, test_index=test_index)\n",
    "# train_dataloader, test_dataloader = dataprepare.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = dataprepare.xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 4, 400])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models import CNNBiLSTM\n",
    "args = Params()\n",
    "clstm = CNNBiLSTM(args)\n",
    "clstm = clstm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clstm(xtest[:31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net = CNNBiLSTM(args).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 394, 2])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(xtest).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import auc, mean_squared_error\n",
    "from torchmetrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0800)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = torch.tensor([[0.1], [0.3]])\n",
    "y = torch.tensor([[0.1], [0.7]])\n",
    "# y = torch.tensor([[0.1, 0.3]])\n",
    "mean_squared_error(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.tensor([[0.1, 0.9], [0.7, 0.3]])\n",
    "y = torch.tensor([[1], [0]])\n",
    "# y = torch.tensor([[0.1, 0.3]])\n",
    "auc(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9000, 0.3000])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['b', 'a'])\n",
    "df['b'] = [1, 2]\n",
    "df['a'] = [3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [4]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['a']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([3]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(3, requires_grad=True)\n",
    "target = torch.empty(3).random_(2)\n",
    "input.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7079, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.tensor([[0.1, 0.9], [0.7, 0.3]])\n",
    "y = torch.tensor([[1], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp = torch.argmax(output, dim=1).reshape(-1, 1)\n",
    "yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5032)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(yp.to(torch.float32), y.to(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from conformer.model import Conformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CTCLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 4, 400])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest = dataprepare.xtest\n",
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN+Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    # adapted from https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.pos_encoder = PositionalEncoding(self.args.out_channels, args.dropout)\n",
    "        self.encoder_layers = TransformerEncoderLayer(d_model=self.args.out_channels, nhead=self.args.nhead, dropout=args.dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(self.encoder_layers, self.args.nlayers, norm=None)\n",
    "        self.decoder = nn.Linear(self.args.out_channels, self.args.out_channels)\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "            No available: src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "class CTransformer(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.cnns = nn.Sequential(\n",
    "            nn.Conv1d(4, 16, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Conv1d(16, args.out_channels, 3),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=1),\n",
    "            nn.BatchNorm1d(args.out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.transformer = TransformerBlock(args)\n",
    "\n",
    "        self.fcn = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(args.fcn_input, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        input [batch_size, channels, seq_len]\n",
    "        \"\"\"\n",
    "        x = self.cnns(x)  # output [batch_size, channels, seq_len]\n",
    "        \n",
    "        x = x.permute(2, 0, 1) # permute to [seq_len, batch_size, channels]\n",
    "        x = self.transformer(x) # output [seq_len, batch_size, channels]\n",
    "        x = x.permute(1, 0, 2) # permute to [batch_size, seq_len, channels]\n",
    "        x = F.relu(x)\n",
    "        x = x.flatten(start_dim=1) # flatten to [batch_size, seq_len * channels]\n",
    "        output = self.fcn(x)\n",
    "        return output\n",
    "\n",
    "# pytorch计算图、梯度相关操作、固定参数训练以及训练过程中grad为Nonetype的原因https://zhuanlan.zhihu.com/p/438630330\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params(object):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.out_channels = 64\n",
    "        self.hidden_size = 256\n",
    "        self.num_layers = 3\n",
    "        self.fcn_input = 25216\n",
    "        self.target = 'valence_label'\n",
    "        self.device = torch.device('cuda')\n",
    "        self.debug = True\n",
    "        self.dropout = 0.2\n",
    "        self.nlayers = 2\n",
    "        self.nhead = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctransformer = CTransformer(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctransformer = ctransformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 25216])\n"
     ]
    }
   ],
   "source": [
    "output = ctransformer(xtest[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import F1Score, Accuracy\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7500), tensor(0.7333))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.tensor([0, 1, 0, 1])\n",
    "preds = torch.tensor([0, 1, 1, 1])\n",
    "accuracy = Accuracy()\n",
    "f1_ = F1Score(average='weighted', num_classes=2)\n",
    "accuracy(preds, target), f1_(preds, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.75, 0.7666666666666667)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(preds.numpy(), target.numpy()), f1_score(preds.numpy(), target.numpy(), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "13e5bb8e298584c2ac3139085defc83b48703aa1260fc05df28d0eb98c842854"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
