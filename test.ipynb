{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "from CONSTANT import *\n",
    "from tools import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import (TensorDataset, DataLoader, SequentialSampler, WeightedRandomSampler)\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "use_cuda = True\n",
    "valid='loso'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and use_cuda else 'cpu')\n",
    "print('using', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPrepare(object):\n",
    "    def __init__(self, target, data, train_index, test_index, batch_size=64,):\n",
    "\n",
    "        X, y = join_signals(data, target=target)\n",
    "        xtrain, ytrain, xtest, ytest = X[train_index], y[train_index], X[test_index], y[test_index]\n",
    "        print(xtrain.shape, ytrain.shape, xtest.shape, ytest.shape)\n",
    "        \n",
    "        self.xtrain = torch.from_numpy(xtrain).to(device).to (torch.float32)\n",
    "        self.xtest = torch.from_numpy(xtest).to(device).to (torch.float32)\n",
    "        \n",
    "        self.ytrain = torch.from_numpy(ytrain).to(device).to (torch.float32)\n",
    "        self.ytest = torch.from_numpy(ytest).to(device).to (torch.float32)\n",
    "        \n",
    "        print(self.xtrain.isnan().any(), self.xtest.isnan().any(), \n",
    "              self.ytrain.isnan().any(), self.ytest.isnan().any(),)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    \n",
    "    def get_data(self):\n",
    "        train_data = TensorDataset(self.xtrain, self.ytrain)\n",
    "        test_data = TensorDataset(self.xtest, self.ytest)\n",
    "        \n",
    "        train_sampler = SequentialSampler(train_data)\n",
    "        train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=self.batch_size, drop_last=True)\n",
    "        \n",
    "        test_sampler = SequentialSampler(test_data)\n",
    "        test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=self.batch_size, drop_last=True)\n",
    "\n",
    "        return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spliter = load_model(r'./processed_signal/HKU956/400_4s_step_2s_spliter.pkl')\n",
    "\n",
    "\n",
    "data = pd.read_pickle(r'./processed_signal/HKU956/400_4s_step_2s.pkl')\n",
    "# data = pd.read_csv(r'./processed_signal/HKU956/400_4s_step_2s.csv')\n",
    "\n",
    "for k in spliter[valid]:\n",
    "    train_index = k['train_index']\n",
    "    test_index = k['test_index']\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18089, 4, 400) (18089,) (4638, 4, 400) (4638,)\n",
      "tensor(False, device='cuda:0') tensor(False, device='cuda:0') tensor(False, device='cuda:0') tensor(False, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "dataprepare = DataPrepare(target='valence', data=data, train_index=train_index, test_index=test_index)\n",
    "# train_dataloader, test_dataloader = dataprepare.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Params(object):\n",
    "#     def __init__(self, lr=0.001, epoch=100, valid='loso', target='valence', batch_size=64,):\n",
    "#         self.batch_size = batch_size\n",
    "#         self.valid = valid\n",
    "#         self.target = target\n",
    "#         self.epoch = epoch\n",
    "#         self.lr = lr\n",
    "#         self.metrics_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 4, 400])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest = dataprepare.xtest[:100]\n",
    "del dataprepare\n",
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtest = xtest.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://blog.csdn.net/Cyril_KI/article/details/125439045\n",
    "# # https://github.com/ozancanozdemir/CNN-LSTM/blob/main/cnn-lstm.py\n",
    "\n",
    "# cnns = nn.Sequential(\n",
    "#     nn.Conv1d(4, 32, 3),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.MaxPool1d(kernel_size=2, stride=1),\n",
    "#     nn.BatchNorm1d(32),\n",
    "#     nn.Conv1d(32, 64, 3),\n",
    "#     nn.MaxPool1d(kernel_size=2, stride=1),\n",
    "#     nn.BatchNorm1d(64),\n",
    "#     nn.ReLU(inplace=True),\n",
    "# )\n",
    "\n",
    "# lstm1 = nn.LSTM(input_size=64, \n",
    "#             hidden_size=256,\n",
    "#             num_layers=3, batch_first=True,\n",
    "#             bidirectional=True, dropout=0.5\n",
    "#             )\n",
    "\n",
    "# lstm2 = nn.LSTM(input_size=256, \n",
    "#             hidden_size=256,\n",
    "#             num_layers=3, batch_first=True,\n",
    "#             bidirectional=True, dropout=0.5\n",
    "#             )\n",
    "    \n",
    "\n",
    "# classifier = nn.Sequential(\n",
    "#             nn.Dropout(p=0.5),\n",
    "#             nn.Linear(256, 1024),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(p=0.5),\n",
    "#             nn.Linear(1024, 512),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(512, 2)\n",
    "#         )\n",
    "\n",
    "# cnns.to(device)\n",
    "# lstm1.to(device)\n",
    "# lstm2.to(device)\n",
    "# classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm = nn.Sequential(nn.LSTM(input_size=64, \n",
    "#             hidden_size=256,\n",
    "#             num_layers=3, batch_first=True,\n",
    "#             bidirectional=True, dropout=0.5\n",
    "#             )).to(device)\n",
    "\n",
    "# lstm2 = nn.LSTM(input_size=512, \n",
    "#             hidden_size=512,\n",
    "#             num_layers=3, batch_first=True,\n",
    "#             bidirectional=True, dropout=0.5\n",
    "#             ).to(device)\n",
    "\n",
    "# bn1 = nn.Sequential(nn.BatchNorm1d(256*2),\n",
    "#                     nn.ReLU(inplace=True),\n",
    "#         ).to(device)\n",
    "\n",
    "# bn2 = nn.Sequential(nn.BatchNorm1d(512*2),\n",
    "#                     nn.ReLU(inplace=True),\n",
    "#         ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = cnns(xtest)\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = cnns(xtest) # output [batch_size, channels, seq_len]\n",
    "# x = x.permute(0, 2, 1)\n",
    "# x, _ = lstm(x) # output [batch_size, seq_len, Hin]\n",
    "# x = x.permute(0, 2, 1)\n",
    "# x = bn1(x)  # output [batch_size, Hin, seq_len]\n",
    "# x = x.permute(0, 2, 1)\n",
    "# x, _ = lstm2(x) # output [batch_size, seq_len, Hin]\n",
    "# x = x.permute(0, 2, 1)\n",
    "# x = bn2(x) # output [batch_size, Hin, seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.flatten(start_dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = cnns(xtest) # output [batch_size, channels, seq_len]\n",
    "# x = x.permute(0, 2, 1)\n",
    "# x, _ = lstms(x) # output [batch_size, seq_len, Hin]\n",
    "# # classifier(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class CNNBiLSTM(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.cnns = nn.Sequential(\n",
    "            nn.Conv1d(4, 32, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Conv1d(32, args.out_channels, 3),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.lstm1 = nn.LSTM(input_size=args.out_channels,\n",
    "                             hidden_size=512,\n",
    "                             num_layers=args.num_layers, batch_first=True,\n",
    "                             bidirectional=True\n",
    "                             )\n",
    "\n",
    "        self.lstm2 = nn.LSTM(input_size=512 * 2,\n",
    "                             hidden_size=args.hidden_size,\n",
    "                             num_layers=args.num_layers, batch_first=True,\n",
    "                             bidirectional=True\n",
    "                             )\n",
    "\n",
    "        self.fcn = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(args.fcn_input, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(512, 2)\n",
    "\n",
    "        self.regresser = nn.Linear(512, 1)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        input [batch_size, channels, seq_len]\n",
    "        \"\"\"\n",
    "        x = self.cnns(x)  # output [batch_size, channels, seq_len]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.lstm1(x)  # output [batch_size, seq_len, Hin]\n",
    "        x = self.relu(x)\n",
    "        x, _ = self.lstm2(x)  # output [batch_size, seq_len, Hin]\n",
    "        x = self.relu(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        print(x.shape)\n",
    "        x = self.fcn(x)\n",
    "        if self.args.target in ['valence', 'arousal']:\n",
    "            return self.regresser(x)\n",
    "        else:\n",
    "            output = torch.sigmoid(self.classifier(x))\n",
    "            return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params(object):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.out_channels = 64\n",
    "        self.hidden_size = 256\n",
    "        self.num_layers = 3\n",
    "        self.fcn_input = 201728\n",
    "        self.target = 'valence_label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 4, 400])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models import CNNBiLSTM\n",
    "args = Params()\n",
    "clstm = CNNBiLSTM(args)\n",
    "clstm = clstm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 201728])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4893, 0.5032],\n",
       "        [0.4895, 0.5027],\n",
       "        [0.4890, 0.5029],\n",
       "        [0.4884, 0.5011],\n",
       "        [0.4906, 0.5014],\n",
       "        [0.4895, 0.5026],\n",
       "        [0.4882, 0.5030],\n",
       "        [0.4882, 0.5025],\n",
       "        [0.4887, 0.5013],\n",
       "        [0.4884, 0.5023],\n",
       "        [0.4887, 0.5035],\n",
       "        [0.4883, 0.5012],\n",
       "        [0.4884, 0.5029],\n",
       "        [0.4898, 0.5018],\n",
       "        [0.4881, 0.5025],\n",
       "        [0.4864, 0.5017],\n",
       "        [0.4888, 0.5022],\n",
       "        [0.4903, 0.5016],\n",
       "        [0.4896, 0.5012],\n",
       "        [0.4887, 0.5024],\n",
       "        [0.4900, 0.5023],\n",
       "        [0.4891, 0.5028],\n",
       "        [0.4890, 0.5014],\n",
       "        [0.4878, 0.5031],\n",
       "        [0.4890, 0.5018],\n",
       "        [0.4877, 0.5039],\n",
       "        [0.4888, 0.5028],\n",
       "        [0.4887, 0.5023],\n",
       "        [0.4894, 0.5010],\n",
       "        [0.4893, 0.5033],\n",
       "        [0.4906, 0.5016]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clstm(xtest[:31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net = CNNBiLSTM(args).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 394, 2])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(xtest).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import auc, mean_squared_error\n",
    "from torchmetrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0800)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = torch.tensor([[0.1], [0.3]])\n",
    "y = torch.tensor([[0.1], [0.7]])\n",
    "# y = torch.tensor([[0.1, 0.3]])\n",
    "mean_squared_error(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.tensor([[0.1, 0.9], [0.7, 0.3]])\n",
    "y = torch.tensor([[1], [0]])\n",
    "# y = torch.tensor([[0.1, 0.3]])\n",
    "auc(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9000, 0.3000])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['b', 'a'])\n",
    "df['b'] = [1, 2]\n",
    "df['a'] = [3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [4]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['a']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2b388c6fce79e00fd9c43dd7c300c62775de93114fdc7222b9aeb8ab89a5a93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
