{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "from CONSTANT import *\n",
    "from tools import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import (TensorDataset, DataLoader, SequentialSampler, WeightedRandomSampler)\n",
    "\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoderLayer, TransformerDecoder\n",
    "\n",
    "from models import *\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "use_cuda = True\n",
    "valid='loso'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and use_cuda else 'cpu')\n",
    "print('using', device)\n",
    "\n",
    "from representation.SigRepre import MultiSignalRepresentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params(object):\n",
    "    def __init__(self, lr=0.001, epoch=100, valid='loso', target='valence', batch_size=64, use_cuda=use_cuda):\n",
    "        self.batch_size = batch_size\n",
    "        self.valid = valid\n",
    "        self.target = target\n",
    "        self.epoch = epoch\n",
    "        self.lr = lr\n",
    "        self.metrics_dict = {}\n",
    "        self.debug = True\n",
    "        self.out_channels = 32\n",
    "        self.out_channels = 32\n",
    "        self.hidden_size = 64\n",
    "        self.num_layers = 1\n",
    "        self.fcn_input = 50432\n",
    "        self.dropout=0.2\n",
    "        self.use_cuda=use_cuda\n",
    "        self.device=torch.device(\n",
    "            'cuda' if torch.cuda.is_available() and self.use_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spliter = load_model(r'./processed_signal/HKU956/400_4s_step_2s_spliter.pkl')\n",
    "data = pd.read_pickle(r'./processed_signal/HKU956/400_4s_step_2s.pkl')\n",
    "# data = pd.read_csv(r'./processed_signal/HKU956/400_4s_step_2s.csv')\n",
    "\n",
    "for k in spliter[valid]:\n",
    "    train_index = k['train_index']\n",
    "    test_index = k['test_index']\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4, 400) (1000, 1) (100, 4, 400) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "args = Params()\n",
    "dataprepare = DataPrepare(args=args, target='valence', data=data, train_index=train_index, test_index=test_index, device=device, batch_size=4)\n",
    "# train_dataloader, test_dataloader = dataprepare.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 4, 400]),\n",
       " torch.Size([1000, 4, 400]),\n",
       " torch.Size([100, 1]),\n",
       " torch.Size([1000, 1]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest = dataprepare.xtest\n",
    "xtrain = dataprepare.xtrain\n",
    "ytest = dataprepare.ytest\n",
    "ytrain = dataprepare.ytrain\n",
    "xtest.shape, xtrain.shape, ytest.shape, ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiSignalRepresentation(output_size=40, device=args.device)\n",
    "# model = model.to(args.device)\n",
    "model.load_state_dict(torch.load(r'./output/0.0001_256_maskp0.8_checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import MER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.output_layer = MER.MERClassifer(args, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xtest[:5]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, test_data = dataprepare.get_data()\n",
    "# encoded_signals = []\n",
    "\n",
    "# for i, (x, y) in tqdm(enumerate(train_data)):\n",
    "#     encodedx = model.encoder(x).flatten(start_dim=1)\n",
    "#     encoded_signals.append(encodedx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_xtrain = model.encoder(xtrain).flatten(start_dim=1)\n",
    "# encoded_xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2b388c6fce79e00fd9c43dd7c300c62775de93114fdc7222b9aeb8ab89a5a93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
